{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohithmsr/AI-practice/blob/main/Opik/1_multi_step_tracing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/static/img/opik-logo.svg\" width=\"250\"/>"
      ],
      "metadata": {
        "id": "9xROyQYP1DM9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ScvGXUo3I80"
      },
      "source": [
        "# Tracking a Multi-step LLM Chain\n",
        "\n",
        "In this exercise, you'll track a multi-step LLM chain with Opik. You can use OpenAI or open source models via LiteLLM.\n",
        "\n",
        "If you have multiple steps in your LLM pipeline, you can use the `track` decorator to log the traces for each step. If OpenAI is called within one of these steps, the LLM call with be associated with that corresponding step:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Configuration"
      ],
      "metadata": {
        "id": "2YJRuver_SmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install opik openai --quiet"
      ],
      "metadata": {
        "id": "hZ6cxMoh3cpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9699b0d2-14a1-48de-9681-aa0316a59f5e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.3/149.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.0/418.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from opik import track\n",
        "import opik\n",
        "from opik.integrations.openai import track_openai\n",
        "from openai import OpenAI\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPIK_PROJECT_NAME\"] = \"Multi-step-Chain-Demo\""
      ],
      "metadata": {
        "id": "Vhy3HZn63ce4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# opik configs\n",
        "if \"OPIK_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPIK_API_KEY\"] = getpass.getpass(\"Enter your Opik API key: \")\n",
        "\n",
        "opik.configure()"
      ],
      "metadata": {
        "id": "ThX2YArw3mda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92244ff-23c5-4cbe-e984-689318e91638"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Opik API key: ··········\n",
            "Do you want to use \"rohithmsr\" workspace? (Y/n)Y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPIK: Configuration saved to file: /root/.opik.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# openai configs\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "client = OpenAI()\n",
        "openai_client = track_openai(client)"
      ],
      "metadata": {
        "id": "T52NO_R73qb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "584e854f-7a1c-45a4-9e20-eb7b75110d83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define First Step"
      ],
      "metadata": {
        "id": "rCOFr4Wd4Frj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@track\n",
        "def generate_meal(ingredient):\n",
        "    prompt = f\"Generate one example of a meal that can be made with {ingredient}.\"\n",
        "    res = openai_client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return res.choices[0].message.content"
      ],
      "metadata": {
        "id": "ZJToIZM6pR5v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Second Step"
      ],
      "metadata": {
        "id": "M-1R6q7W4JnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@track\n",
        "def generate_recipe(meal):\n",
        "    prompt = f\"Generate a step-by-step recipe for {meal}\"\n",
        "    res = openai_client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return res.choices[0].message.content"
      ],
      "metadata": {
        "id": "Z_iBzyQgpvEo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Call Chain"
      ],
      "metadata": {
        "id": "H_Wc5RDhCaJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@track\n",
        "def generate_recipe_from_ingredient(ingredient):\n",
        "    meal = generate_meal(ingredient)\n",
        "    story = generate_recipe(meal)\n",
        "    return story\n",
        "\n",
        "generate_recipe_from_ingredient(\"tender coconut\")"
      ],
      "metadata": {
        "id": "K6WmeCQ4p6js",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "059501ed-6d0e-4e4e-990e-f8a2b6d66a78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ingredients:\\n- 1 cup of white rice\\n- 1 cup of coconut milk\\n- 1 cup of water\\n- 1/2 cup of tender coconut pieces\\n- 1/4 cup of shredded coconut\\n- Salt and pepper to taste\\n- 4 fish fillets\\n- 1/2 cup of coconut milk\\n- 1 tablespoon of lime juice\\n- 1 tablespoon of soy sauce\\n- 1 tablespoon of honey\\n- 1 teaspoon of minced garlic\\n- 1 teaspoon of minced ginger\\n- 1 tablespoon of vegetable oil\\n\\nInstructions:\\n\\n1. In a saucepan, combine the rice, coconut milk, water, tender coconut pieces, shredded coconut, salt, and pepper. Bring to a boil, then reduce heat to low and let simmer for about 20 minutes or until the rice is cooked and the liquid is absorbed.\\n\\n2. In a separate bowl, mix together the coconut milk, lime juice, soy sauce, honey, garlic, and ginger to make the coconut milk sauce. Set aside.\\n\\n3. Season the fish fillets with salt and pepper. Heat the vegetable oil in a grill pan over medium heat. Grill the fish fillets for about 3-4 minutes on each side, or until cooked through.\\n\\n4. Serve the coconut rice on a plate, top with the grilled fish fillets, and drizzle with the coconut milk sauce.\\n\\n5. Enjoy your delicious coconut rice with tender coconut pieces and shredded coconut, served with a side of grilled fish and a coconut milk sauce!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try with your own example!"
      ],
      "metadata": {
        "id": "4fRPxqyFq83h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_recipe_from_ingredient(input(\"Enter an ingredient: \"))"
      ],
      "metadata": {
        "id": "SYgndLdprBQ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "a62a2d4d-8b02-4cc8-b942-c1d5ac9cf620"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter an ingredient: Horsegram\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n11. You can also add a squeeze of lemon juice before serving for an extra burst of flavor.\\n12. This dish can be made vegan by using vegetable oil instead of ghee.\\n13. Feel free to add in other vegetables like carrots, peas, or bell peppers for added nutrition and texture. \\n14. Leftovers can be stored in an airtight container in the refrigerator for up to 3-4 days. Reheat before serving. Enjoy!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CUJcinyP1m1V"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "comet-eval",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2YJRuver_SmK",
        "rCOFr4Wd4Frj",
        "M-1R6q7W4JnZ",
        "H_Wc5RDhCaJs",
        "4fRPxqyFq83h"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}